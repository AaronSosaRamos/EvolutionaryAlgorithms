{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Genetic Algorithms (GA)"
      ],
      "metadata": {
        "id": "3aTjyZwaHeWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Genetic algorithms are one of the most well-known types of evolutionary algorithms.\n",
        "* They use the concepts of natural selection and genetics to solve optimization problems by evolving a population of potential solutions.\n",
        "* GA involves encoding potential solutions into chromosomes (typically binary strings), using selection operators (like tournament selection), crossover (recombination of chromosomes), and mutation (introducing random changes).\n",
        "* Genetic algorithms are widely applied in optimization, search, and machine learning tasks."
      ],
      "metadata": {
        "id": "NnhiswReHgoL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Standard Genetic Algorithm (SGA):\n",
        "\n"
      ],
      "metadata": {
        "id": "dtPpuDn_HyfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traditional genetic algorithm using binary encoding, selection (e.g., roulette wheel or tournament selection), crossover (e.g., single-point or multi-point crossover), and mutation (flipping bits)."
      ],
      "metadata": {
        "id": "dnlGMU0qHzT6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zzg2k5MqHbdh",
        "outputId": "37a518a4-12be-4300-dc1f-0f26f1ca5a8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1, Best Fitness: 8\n",
            "Generation 2, Best Fitness: 10\n",
            "Generation 3, Best Fitness: 9\n",
            "Generation 4, Best Fitness: 9\n",
            "Generation 5, Best Fitness: 9\n",
            "Generation 6, Best Fitness: 9\n",
            "Generation 7, Best Fitness: 9\n",
            "Generation 8, Best Fitness: 9\n",
            "Generation 9, Best Fitness: 9\n",
            "Generation 10, Best Fitness: 9\n",
            "Generation 11, Best Fitness: 10\n",
            "Generation 12, Best Fitness: 9\n",
            "Generation 13, Best Fitness: 9\n",
            "Generation 14, Best Fitness: 9\n",
            "Generation 15, Best Fitness: 9\n",
            "Generation 16, Best Fitness: 10\n",
            "Generation 17, Best Fitness: 10\n",
            "Generation 18, Best Fitness: 10\n",
            "Generation 19, Best Fitness: 10\n",
            "Generation 20, Best Fitness: 10\n",
            "Generation 21, Best Fitness: 10\n",
            "Generation 22, Best Fitness: 10\n",
            "Generation 23, Best Fitness: 10\n",
            "Generation 24, Best Fitness: 10\n",
            "Generation 25, Best Fitness: 10\n",
            "Generation 26, Best Fitness: 10\n",
            "Generation 27, Best Fitness: 10\n",
            "Generation 28, Best Fitness: 10\n",
            "Generation 29, Best Fitness: 10\n",
            "Generation 30, Best Fitness: 10\n",
            "Generation 31, Best Fitness: 10\n",
            "Generation 32, Best Fitness: 10\n",
            "Generation 33, Best Fitness: 10\n",
            "Generation 34, Best Fitness: 10\n",
            "Generation 35, Best Fitness: 10\n",
            "Generation 36, Best Fitness: 10\n",
            "Generation 37, Best Fitness: 10\n",
            "Generation 38, Best Fitness: 10\n",
            "Generation 39, Best Fitness: 10\n",
            "Generation 40, Best Fitness: 10\n",
            "Generation 41, Best Fitness: 10\n",
            "Generation 42, Best Fitness: 10\n",
            "Generation 43, Best Fitness: 10\n",
            "Generation 44, Best Fitness: 10\n",
            "Generation 45, Best Fitness: 10\n",
            "Generation 46, Best Fitness: 10\n",
            "Generation 47, Best Fitness: 10\n",
            "Generation 48, Best Fitness: 10\n",
            "Generation 49, Best Fitness: 10\n",
            "Generation 50, Best Fitness: 10\n",
            "Best Solution: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], Best Fitness: 10\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "class GeneticAlgorithm:\n",
        "    def __init__(self, population_size, chromosome_length, crossover_rate, mutation_rate, generations):\n",
        "        self.population_size = population_size\n",
        "        self.chromosome_length = chromosome_length\n",
        "        self.crossover_rate = crossover_rate\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.generations = generations\n",
        "        self.population = []\n",
        "\n",
        "    def initialize_population(self):\n",
        "        self.population = [[random.randint(0, 1) for _ in range(self.chromosome_length)] for _ in range(self.population_size)]\n",
        "\n",
        "    def fitness(self, chromosome):\n",
        "        # Define a simple fitness function - count of '1's in the chromosome\n",
        "        return sum(chromosome)\n",
        "\n",
        "    def selection(self):\n",
        "        # Roulette wheel selection\n",
        "        fitness_values = [self.fitness(chromosome) for chromosome in self.population]\n",
        "        total_fitness = sum(fitness_values)\n",
        "        probabilities = [fitness / total_fitness for fitness in fitness_values]\n",
        "        selected_indices = random.choices(range(self.population_size), weights=probabilities, k=2)\n",
        "        return [self.population[selected_indices[0]], self.population[selected_indices[1]]]\n",
        "\n",
        "    def crossover(self, parent1, parent2):\n",
        "        # Single-point crossover\n",
        "        if random.random() < self.crossover_rate:\n",
        "            crossover_point = random.randint(1, self.chromosome_length - 1)\n",
        "            child1 = parent1[:crossover_point] + parent2[crossover_point:]\n",
        "            child2 = parent2[:crossover_point] + parent1[crossover_point:]\n",
        "            return child1, child2\n",
        "        else:\n",
        "            return parent1, parent2\n",
        "\n",
        "    def mutation(self, chromosome):\n",
        "        # Flip bits with mutation rate\n",
        "        mutated_chromosome = [bit ^ (random.random() < self.mutation_rate) for bit in chromosome]\n",
        "        return mutated_chromosome\n",
        "\n",
        "    def evolve(self):\n",
        "        self.initialize_population()\n",
        "\n",
        "        for generation in range(self.generations):\n",
        "            new_population = []\n",
        "\n",
        "            while len(new_population) < self.population_size:\n",
        "                # Selection\n",
        "                parent1, parent2 = self.selection()\n",
        "\n",
        "                # Crossover\n",
        "                child1, child2 = self.crossover(parent1, parent2)\n",
        "\n",
        "                # Mutation\n",
        "                child1 = self.mutation(child1)\n",
        "                child2 = self.mutation(child2)\n",
        "\n",
        "                new_population.append(child1)\n",
        "                new_population.append(child2)\n",
        "\n",
        "            self.population = new_population\n",
        "\n",
        "            # Print best fitness in the current generation\n",
        "            best_fitness = max([self.fitness(chromosome) for chromosome in self.population])\n",
        "            print(f\"Generation {generation + 1}, Best Fitness: {best_fitness}\")\n",
        "\n",
        "        # Return the best solution after all generations\n",
        "        best_chromosome = max(self.population, key=self.fitness)\n",
        "        best_fitness = self.fitness(best_chromosome)\n",
        "        print(f\"Best Solution: {best_chromosome}, Best Fitness: {best_fitness}\")\n",
        "\n",
        "# Example usage:\n",
        "ga = GeneticAlgorithm(population_size=50, chromosome_length=10, crossover_rate=0.8, mutation_rate=0.01, generations=50)\n",
        "ga.evolve()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "ga = GeneticAlgorithm(population_size=100, chromosome_length=20, crossover_rate=0.6, mutation_rate=0.01, generations=50)\n",
        "ga.evolve()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpSgh_9mIOR6",
        "outputId": "1b22b954-311f-42e2-d38b-068c162826e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1, Best Fitness: 17\n",
            "Generation 2, Best Fitness: 17\n",
            "Generation 3, Best Fitness: 17\n",
            "Generation 4, Best Fitness: 18\n",
            "Generation 5, Best Fitness: 16\n",
            "Generation 6, Best Fitness: 16\n",
            "Generation 7, Best Fitness: 17\n",
            "Generation 8, Best Fitness: 17\n",
            "Generation 9, Best Fitness: 17\n",
            "Generation 10, Best Fitness: 17\n",
            "Generation 11, Best Fitness: 17\n",
            "Generation 12, Best Fitness: 17\n",
            "Generation 13, Best Fitness: 17\n",
            "Generation 14, Best Fitness: 19\n",
            "Generation 15, Best Fitness: 18\n",
            "Generation 16, Best Fitness: 17\n",
            "Generation 17, Best Fitness: 17\n",
            "Generation 18, Best Fitness: 18\n",
            "Generation 19, Best Fitness: 18\n",
            "Generation 20, Best Fitness: 18\n",
            "Generation 21, Best Fitness: 18\n",
            "Generation 22, Best Fitness: 18\n",
            "Generation 23, Best Fitness: 18\n",
            "Generation 24, Best Fitness: 18\n",
            "Generation 25, Best Fitness: 18\n",
            "Generation 26, Best Fitness: 19\n",
            "Generation 27, Best Fitness: 18\n",
            "Generation 28, Best Fitness: 18\n",
            "Generation 29, Best Fitness: 19\n",
            "Generation 30, Best Fitness: 19\n",
            "Generation 31, Best Fitness: 19\n",
            "Generation 32, Best Fitness: 18\n",
            "Generation 33, Best Fitness: 19\n",
            "Generation 34, Best Fitness: 19\n",
            "Generation 35, Best Fitness: 19\n",
            "Generation 36, Best Fitness: 19\n",
            "Generation 37, Best Fitness: 19\n",
            "Generation 38, Best Fitness: 19\n",
            "Generation 39, Best Fitness: 19\n",
            "Generation 40, Best Fitness: 19\n",
            "Generation 41, Best Fitness: 20\n",
            "Generation 42, Best Fitness: 20\n",
            "Generation 43, Best Fitness: 20\n",
            "Generation 44, Best Fitness: 20\n",
            "Generation 45, Best Fitness: 20\n",
            "Generation 46, Best Fitness: 20\n",
            "Generation 47, Best Fitness: 20\n",
            "Generation 48, Best Fitness: 19\n",
            "Generation 49, Best Fitness: 19\n",
            "Generation 50, Best Fitness: 19\n",
            "Best Solution: [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], Best Fitness: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization with Genetic Algorithm"
      ],
      "metadata": {
        "id": "XEsXeuI9IwWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Fitness function: Minimize the square of the difference from the target value\n",
        "def fitness_function(chromosome):\n",
        "    target_value = 50\n",
        "    value = sum(chromosome)\n",
        "    return -(value - target_value)**2  # Negative squared difference as fitness\n",
        "\n",
        "class GeneticAlgorithm:\n",
        "    def __init__(self, population_size, chromosome_length, crossover_rate, mutation_rate, generations):\n",
        "        self.population_size = population_size\n",
        "        self.chromosome_length = chromosome_length\n",
        "        self.crossover_rate = crossover_rate\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.generations = generations\n",
        "        self.population = []\n",
        "\n",
        "    def initialize_population(self):\n",
        "        self.population = [[random.randint(0, 1) for _ in range(self.chromosome_length)] for _ in range(self.population_size)]\n",
        "\n",
        "    def selection(self):\n",
        "        fitness_values = [fitness_function(chromosome) for chromosome in self.population]\n",
        "        total_fitness = sum(fitness_values)\n",
        "        probabilities = [fitness / total_fitness for fitness in fitness_values]\n",
        "        selected_indices = random.choices(range(self.population_size), weights=probabilities, k=2)\n",
        "        return [self.population[selected_indices[0]], self.population[selected_indices[1]]]\n",
        "\n",
        "    def crossover(self, parent1, parent2):\n",
        "        if random.random() < self.crossover_rate:\n",
        "            crossover_point = random.randint(1, self.chromosome_length - 1)\n",
        "            child1 = parent1[:crossover_point] + parent2[crossover_point:]\n",
        "            child2 = parent2[:crossover_point] + parent1[crossover_point:]\n",
        "            return child1, child2\n",
        "        else:\n",
        "            return parent1, parent2\n",
        "\n",
        "    def mutation(self, chromosome):\n",
        "        mutated_chromosome = [bit ^ (random.random() < self.mutation_rate) for bit in chromosome]\n",
        "        return mutated_chromosome\n",
        "\n",
        "    def evolve(self):\n",
        "        self.initialize_population()\n",
        "\n",
        "        for generation in range(self.generations):\n",
        "            new_population = []\n",
        "\n",
        "            while len(new_population) < self.population_size:\n",
        "                parent1, parent2 = self.selection()\n",
        "                child1, child2 = self.crossover(parent1, parent2)\n",
        "                child1 = self.mutation(child1)\n",
        "                child2 = self.mutation(child2)\n",
        "                new_population.append(child1)\n",
        "                new_population.append(child2)\n",
        "\n",
        "            self.population = new_population\n",
        "\n",
        "            # Print best fitness in the current generation\n",
        "            best_fitness = max([fitness_function(chromosome) for chromosome in self.population])\n",
        "            print(f\"Generation {generation + 1}, Best Fitness: {best_fitness}\")\n",
        "\n",
        "        # Return the best solution after all generations\n",
        "        best_chromosome = max(self.population, key=fitness_function)\n",
        "        best_fitness = fitness_function(best_chromosome)\n",
        "        print(f\"Best Solution: {best_chromosome}, Best Fitness: {best_fitness}\")\n",
        "\n",
        "# Example usage for optimization task\n",
        "ga = GeneticAlgorithm(population_size=50, chromosome_length=10, crossover_rate=0.8, mutation_rate=0.01, generations=50)\n",
        "ga.evolve()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jlR7TnCIwkh",
        "outputId": "03d2faec-3fdb-4aa1-e963-543675c782a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1, Best Fitness: -1764\n",
            "Generation 2, Best Fitness: -1764\n",
            "Generation 3, Best Fitness: -1764\n",
            "Generation 4, Best Fitness: -1764\n",
            "Generation 5, Best Fitness: -1849\n",
            "Generation 6, Best Fitness: -1764\n",
            "Generation 7, Best Fitness: -1849\n",
            "Generation 8, Best Fitness: -1849\n",
            "Generation 9, Best Fitness: -1764\n",
            "Generation 10, Best Fitness: -1764\n",
            "Generation 11, Best Fitness: -1764\n",
            "Generation 12, Best Fitness: -1849\n",
            "Generation 13, Best Fitness: -1764\n",
            "Generation 14, Best Fitness: -1936\n",
            "Generation 15, Best Fitness: -1849\n",
            "Generation 16, Best Fitness: -1681\n",
            "Generation 17, Best Fitness: -1936\n",
            "Generation 18, Best Fitness: -1936\n",
            "Generation 19, Best Fitness: -1936\n",
            "Generation 20, Best Fitness: -1936\n",
            "Generation 21, Best Fitness: -1936\n",
            "Generation 22, Best Fitness: -1849\n",
            "Generation 23, Best Fitness: -1849\n",
            "Generation 24, Best Fitness: -1849\n",
            "Generation 25, Best Fitness: -1849\n",
            "Generation 26, Best Fitness: -1849\n",
            "Generation 27, Best Fitness: -1764\n",
            "Generation 28, Best Fitness: -1849\n",
            "Generation 29, Best Fitness: -1849\n",
            "Generation 30, Best Fitness: -1936\n",
            "Generation 31, Best Fitness: -1936\n",
            "Generation 32, Best Fitness: -2025\n",
            "Generation 33, Best Fitness: -1936\n",
            "Generation 34, Best Fitness: -2025\n",
            "Generation 35, Best Fitness: -2025\n",
            "Generation 36, Best Fitness: -2025\n",
            "Generation 37, Best Fitness: -2025\n",
            "Generation 38, Best Fitness: -2025\n",
            "Generation 39, Best Fitness: -1936\n",
            "Generation 40, Best Fitness: -1849\n",
            "Generation 41, Best Fitness: -1936\n",
            "Generation 42, Best Fitness: -1849\n",
            "Generation 43, Best Fitness: -1849\n",
            "Generation 44, Best Fitness: -1849\n",
            "Generation 45, Best Fitness: -1764\n",
            "Generation 46, Best Fitness: -1849\n",
            "Generation 47, Best Fitness: -1936\n",
            "Generation 48, Best Fitness: -1936\n",
            "Generation 49, Best Fitness: -1936\n",
            "Generation 50, Best Fitness: -2116\n",
            "Best Solution: [0, 0, 1, 0, 1, 0, 1, 0, 0, 1], Best Fitness: -2116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameter Tuning with Genetic Algorithm"
      ],
      "metadata": {
        "id": "nG9pU5REI2pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Fitness function: Train a RandomForestClassifier with given hyperparameters and return accuracy\n",
        "def fitness_function(params):\n",
        "    n_estimators, max_depth = params\n",
        "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    return accuracy_score(y_test, y_pred)\n",
        "\n",
        "class GeneticAlgorithm:\n",
        "    def __init__(self, population_size, generations):\n",
        "        self.population_size = population_size\n",
        "        self.generations = generations\n",
        "        self.population = []\n",
        "\n",
        "    def initialize_population(self):\n",
        "        self.population = [(random.randint(10, 100), random.randint(2, 20)) for _ in range(self.population_size)]\n",
        "\n",
        "    def selection(self):\n",
        "        return random.choices(self.population, k=2)\n",
        "\n",
        "    def crossover(self, parent1, parent2):\n",
        "        crossover_point = random.randint(0, 1)\n",
        "        child1 = (parent1[0], parent2[1])  # Crossover n_estimators\n",
        "        child2 = (parent2[0], parent1[1])  # Crossover max_depth\n",
        "        return child1, child2\n",
        "\n",
        "    def mutation(self, chromosome):\n",
        "        param_idx = random.randint(0, 1)\n",
        "        mutated_value = random.randint(10, 100) if param_idx == 0 else random.randint(2, 20)\n",
        "        mutated_chromosome = list(chromosome)\n",
        "        mutated_chromosome[param_idx] = mutated_value\n",
        "        return tuple(mutated_chromosome)\n",
        "\n",
        "    def evolve(self):\n",
        "        self.initialize_population()\n",
        "\n",
        "        for generation in range(self.generations):\n",
        "            new_population = []\n",
        "\n",
        "            while len(new_population) < self.population_size:\n",
        "                parent1, parent2 = self.selection()\n",
        "                child1, child2 = self.crossover(parent1, parent2)\n",
        "                child1 = self.mutation(child1)\n",
        "                child2 = self.mutation(child2)\n",
        "                new_population.append(child1)\n",
        "                new_population.append(child2)\n",
        "\n",
        "            self.population = new_population\n",
        "\n",
        "            # Print best fitness in the current generation\n",
        "            best_params = max(self.population, key=fitness_function)\n",
        "            best_fitness = fitness_function(best_params)\n",
        "            print(f\"Generation {generation + 1}, Best Fitness: {best_fitness}\")\n",
        "\n",
        "        # Return the best solution after all generations\n",
        "        best_params = max(self.population, key=fitness_function)\n",
        "        best_fitness = fitness_function(best_params)\n",
        "        print(f\"Best Parameters: {best_params}, Best Fitness: {best_fitness}\")\n",
        "\n",
        "# Example usage for parameter tuning task\n",
        "ga = GeneticAlgorithm(population_size=50, generations=20)\n",
        "ga.evolve()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC7cypCvI26R",
        "outputId": "c17caa1f-ca7e-48fb-f16b-65dde9c9ba32"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1, Best Fitness: 1.0\n",
            "Generation 2, Best Fitness: 1.0\n",
            "Generation 3, Best Fitness: 1.0\n",
            "Generation 4, Best Fitness: 1.0\n",
            "Generation 5, Best Fitness: 1.0\n",
            "Generation 6, Best Fitness: 1.0\n",
            "Generation 7, Best Fitness: 1.0\n",
            "Generation 8, Best Fitness: 1.0\n",
            "Generation 9, Best Fitness: 1.0\n",
            "Generation 10, Best Fitness: 1.0\n",
            "Generation 11, Best Fitness: 1.0\n",
            "Generation 12, Best Fitness: 1.0\n",
            "Generation 13, Best Fitness: 1.0\n",
            "Generation 14, Best Fitness: 1.0\n",
            "Generation 15, Best Fitness: 1.0\n",
            "Generation 16, Best Fitness: 1.0\n",
            "Generation 17, Best Fitness: 1.0\n",
            "Generation 18, Best Fitness: 1.0\n",
            "Generation 19, Best Fitness: 1.0\n",
            "Generation 20, Best Fitness: 1.0\n",
            "Best Parameters: (95, 7), Best Fitness: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2, Chromosome Reuse Genetic Algorithm (CRGA)"
      ],
      "metadata": {
        "id": "kKJDCUlTJxvZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Focuses on reusing successful chromosomes from previous generations to speed up convergence."
      ],
      "metadata": {
        "id": "Df0wLNM5Jzjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import copy\n",
        "\n",
        "class Chromosome:\n",
        "    def __init__(self, genes):\n",
        "        self.genes = genes\n",
        "        self.fitness = None\n",
        "\n",
        "def create_initial_population(population_size, gene_length):\n",
        "    population = []\n",
        "    for _ in range(population_size):\n",
        "        genes = [random.randint(0, 1) for _ in range(gene_length)]\n",
        "        population.append(Chromosome(genes))\n",
        "    return population\n",
        "\n",
        "def evaluate_population(population, fitness_function):\n",
        "    for chromosome in population:\n",
        "        if chromosome.fitness is None:\n",
        "            chromosome.fitness = fitness_function(chromosome.genes)\n",
        "\n",
        "def select_individuals(population, num_parents):\n",
        "    # Tournament selection\n",
        "    selected_parents = []\n",
        "    population_copy = population[:]\n",
        "    for _ in range(num_parents):\n",
        "        tournament_size = 3\n",
        "        tournament_contestants = random.sample(population_copy, tournament_size)\n",
        "        winner = max(tournament_contestants, key=lambda x: x.fitness if x.fitness is not None else float('-inf'))\n",
        "        selected_parents.append(winner)\n",
        "        population_copy.remove(winner)\n",
        "    return selected_parents\n",
        "\n",
        "def crossover(parent1, parent2):\n",
        "    # Single-point crossover\n",
        "    crossover_point = random.randint(1, len(parent1.genes) - 1)\n",
        "    child1_genes = parent1.genes[:crossover_point] + parent2.genes[crossover_point:]\n",
        "    child2_genes = parent2.genes[:crossover_point] + parent1.genes[crossover_point:]\n",
        "    return Chromosome(child1_genes), Chromosome(child2_genes)\n",
        "\n",
        "def mutate(chromosome, mutation_rate):\n",
        "    mutated_genes = []\n",
        "    for gene in chromosome.genes:\n",
        "        if random.random() < mutation_rate:\n",
        "            mutated_genes.append(1 - gene)  # Flip the bit\n",
        "        else:\n",
        "            mutated_genes.append(gene)\n",
        "    return Chromosome(mutated_genes)\n",
        "\n",
        "def chromosome_reuse_genetic_algorithm(population_size, gene_length, fitness_function, num_generations, reuse_rate=0.5):\n",
        "    population = create_initial_population(population_size, gene_length)\n",
        "    best_chromosome = None\n",
        "\n",
        "    for generation in range(num_generations):\n",
        "        evaluate_population(population, fitness_function)\n",
        "\n",
        "        # Sort population by fitness (descending order)\n",
        "        population.sort(key=lambda x: x.fitness if x.fitness is not None else float('-inf'), reverse=True)\n",
        "\n",
        "        # Select top chromosomes for reproduction\n",
        "        num_parents = int(reuse_rate * population_size)\n",
        "        parents = select_individuals(population, num_parents)\n",
        "\n",
        "        # Create offspring through crossover and mutation\n",
        "        offspring = []\n",
        "        while len(offspring) < population_size - num_parents:\n",
        "            parent1 = random.choice(parents)\n",
        "            parent2 = random.choice(parents)\n",
        "            child1, child2 = crossover(parent1, parent2)\n",
        "            child1 = mutate(child1, mutation_rate=0.1)\n",
        "            child2 = mutate(child2, mutation_rate=0.1)\n",
        "            offspring.append(child1)\n",
        "            offspring.append(child2)\n",
        "\n",
        "        # Replace the old population with the new population\n",
        "        population = parents + offspring\n",
        "\n",
        "        # Track the best chromosome in this generation\n",
        "        current_best = max(population, key=lambda x: x.fitness if x.fitness is not None else float('-inf'))\n",
        "        if best_chromosome is None or (current_best.fitness is not None and current_best.fitness > best_chromosome.fitness):\n",
        "            best_chromosome = copy.deepcopy(current_best)\n",
        "\n",
        "        print(f\"Generation {generation + 1}: Best Fitness = {best_chromosome.fitness}\")\n",
        "\n",
        "    return best_chromosome\n",
        "\n",
        "# Example fitness function (maximizing the number of 1s)\n",
        "def fitness_function(genes):\n",
        "    return sum(genes)\n",
        "\n",
        "# Usage example\n",
        "best_solution = chromosome_reuse_genetic_algorithm(\n",
        "    population_size=50,\n",
        "    gene_length=20,\n",
        "    fitness_function=fitness_function,\n",
        "    num_generations=50,\n",
        "    reuse_rate=0.5\n",
        ")\n",
        "\n",
        "print(\"\\nBest Solution Found:\")\n",
        "print(\"Genes:\", best_solution.genes)\n",
        "print(\"Fitness:\", best_solution.fitness)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppDirTpnJu_5",
        "outputId": "d62b47c1-580a-42de-bd3b-7385fb193f3a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1: Best Fitness = 17\n",
            "Generation 2: Best Fitness = 17\n",
            "Generation 3: Best Fitness = 17\n",
            "Generation 4: Best Fitness = 17\n",
            "Generation 5: Best Fitness = 17\n",
            "Generation 6: Best Fitness = 17\n",
            "Generation 7: Best Fitness = 17\n",
            "Generation 8: Best Fitness = 17\n",
            "Generation 9: Best Fitness = 18\n",
            "Generation 10: Best Fitness = 18\n",
            "Generation 11: Best Fitness = 18\n",
            "Generation 12: Best Fitness = 19\n",
            "Generation 13: Best Fitness = 19\n",
            "Generation 14: Best Fitness = 19\n",
            "Generation 15: Best Fitness = 19\n",
            "Generation 16: Best Fitness = 19\n",
            "Generation 17: Best Fitness = 20\n",
            "Generation 18: Best Fitness = 20\n",
            "Generation 19: Best Fitness = 20\n",
            "Generation 20: Best Fitness = 20\n",
            "Generation 21: Best Fitness = 20\n",
            "Generation 22: Best Fitness = 20\n",
            "Generation 23: Best Fitness = 20\n",
            "Generation 24: Best Fitness = 20\n",
            "Generation 25: Best Fitness = 20\n",
            "Generation 26: Best Fitness = 20\n",
            "Generation 27: Best Fitness = 20\n",
            "Generation 28: Best Fitness = 20\n",
            "Generation 29: Best Fitness = 20\n",
            "Generation 30: Best Fitness = 20\n",
            "Generation 31: Best Fitness = 20\n",
            "Generation 32: Best Fitness = 20\n",
            "Generation 33: Best Fitness = 20\n",
            "Generation 34: Best Fitness = 20\n",
            "Generation 35: Best Fitness = 20\n",
            "Generation 36: Best Fitness = 20\n",
            "Generation 37: Best Fitness = 20\n",
            "Generation 38: Best Fitness = 20\n",
            "Generation 39: Best Fitness = 20\n",
            "Generation 40: Best Fitness = 20\n",
            "Generation 41: Best Fitness = 20\n",
            "Generation 42: Best Fitness = 20\n",
            "Generation 43: Best Fitness = 20\n",
            "Generation 44: Best Fitness = 20\n",
            "Generation 45: Best Fitness = 20\n",
            "Generation 46: Best Fitness = 20\n",
            "Generation 47: Best Fitness = 20\n",
            "Generation 48: Best Fitness = 20\n",
            "Generation 49: Best Fitness = 20\n",
            "Generation 50: Best Fitness = 20\n",
            "\n",
            "Best Solution Found:\n",
            "Genes: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Fitness: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Steady-State Genetic Algorithm:"
      ],
      "metadata": {
        "id": "hNcSzK1qPbPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintains a fixed population size by replacing less fit individuals with newly generated ones, often using tournament selection."
      ],
      "metadata": {
        "id": "SWATPg9-Rxd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class GeneticAlgorithm:\n",
        "    def __init__(self, population_size, crossover_rate, mutation_rate, tournament_size):\n",
        "        self.population_size = population_size\n",
        "        self.crossover_rate = crossover_rate\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.tournament_size = tournament_size\n",
        "        self.population = []\n",
        "\n",
        "    def initialize_population(self, individual_generator):\n",
        "        self.population = [individual_generator() for _ in range(self.population_size)]\n",
        "\n",
        "    def evolve(self, fitness_func, num_generations):\n",
        "        for generation in range(num_generations):\n",
        "            new_population = []\n",
        "            for _ in range(self.population_size):\n",
        "                # Select parents for crossover using tournament selection\n",
        "                parent1 = self.tournament_selection(fitness_func)\n",
        "                parent2 = self.tournament_selection(fitness_func)\n",
        "\n",
        "                # Apply crossover to create offspring\n",
        "                offspring = self.crossover(parent1, parent2) if random.random() < self.crossover_rate else parent1\n",
        "\n",
        "                # Apply mutation to the offspring\n",
        "                offspring = self.mutate(offspring) if random.random() < self.mutation_rate else offspring\n",
        "\n",
        "                # Add offspring to the new population\n",
        "                new_population.append(offspring)\n",
        "\n",
        "            # Replace individuals in the population with new population\n",
        "            self.replace_population(new_population, fitness_func)\n",
        "\n",
        "            # Optional: Monitor or record the best individual in this generation\n",
        "            best_individual = max(self.population, key=fitness_func)\n",
        "            print(f\"Generation {generation + 1}, Best Fitness: {fitness_func(best_individual)}\")\n",
        "\n",
        "    def tournament_selection(self, fitness_func):\n",
        "        # Randomly select individuals for the tournament\n",
        "        tournament_contestants = random.sample(self.population, self.tournament_size)\n",
        "        # Return the best contestant based on fitness\n",
        "        return max(tournament_contestants, key=fitness_func)\n",
        "\n",
        "    def crossover(self, parent1, parent2):\n",
        "        # Example: Single-point crossover\n",
        "        crossover_point = random.randint(0, min(len(parent1), len(parent2)) - 1)\n",
        "        return parent1[:crossover_point] + parent2[crossover_point:]\n",
        "\n",
        "    def mutate(self, individual):\n",
        "        # Example: Bit-wise mutation (flipping a random bit)\n",
        "        mutate_index = random.randint(0, len(individual) - 1)\n",
        "        mutated_individual = list(individual)\n",
        "        mutated_individual[mutate_index] = 1 - mutated_individual[mutate_index]  # Flip 0 to 1 or 1 to 0\n",
        "        return tuple(mutated_individual)\n",
        "\n",
        "    def replace_population(self, new_population, fitness_func):\n",
        "        # Replace less fit individuals in the current population with new population\n",
        "        for i in range(self.population_size):\n",
        "            if fitness_func(new_population[i]) > fitness_func(self.population[i]):\n",
        "                self.population[i] = new_population[i]\n",
        "\n",
        "# Example usage:\n",
        "def generate_random_individual():\n",
        "    # Generate a random individual (e.g., binary string)\n",
        "    return tuple(random.randint(0, 1) for _ in range(10))  # 10-bit individual\n",
        "\n",
        "def calculate_fitness(individual):\n",
        "    # Example fitness function (count of 1s in the individual)\n",
        "    return sum(individual)\n",
        "\n",
        "# Initialize and run the genetic algorithm\n",
        "ga = GeneticAlgorithm(population_size=50, crossover_rate=0.8, mutation_rate=0.01, tournament_size=3)\n",
        "ga.initialize_population(generate_random_individual)\n",
        "ga.evolve(calculate_fitness, num_generations=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOSA9AoPR4C-",
        "outputId": "42b31edd-815b-4fcf-8fdb-64c7e30fc2f2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1, Best Fitness: 9\n",
            "Generation 2, Best Fitness: 9\n",
            "Generation 3, Best Fitness: 10\n",
            "Generation 4, Best Fitness: 10\n",
            "Generation 5, Best Fitness: 10\n",
            "Generation 6, Best Fitness: 10\n",
            "Generation 7, Best Fitness: 10\n",
            "Generation 8, Best Fitness: 10\n",
            "Generation 9, Best Fitness: 10\n",
            "Generation 10, Best Fitness: 10\n",
            "Generation 11, Best Fitness: 10\n",
            "Generation 12, Best Fitness: 10\n",
            "Generation 13, Best Fitness: 10\n",
            "Generation 14, Best Fitness: 10\n",
            "Generation 15, Best Fitness: 10\n",
            "Generation 16, Best Fitness: 10\n",
            "Generation 17, Best Fitness: 10\n",
            "Generation 18, Best Fitness: 10\n",
            "Generation 19, Best Fitness: 10\n",
            "Generation 20, Best Fitness: 10\n",
            "Generation 21, Best Fitness: 10\n",
            "Generation 22, Best Fitness: 10\n",
            "Generation 23, Best Fitness: 10\n",
            "Generation 24, Best Fitness: 10\n",
            "Generation 25, Best Fitness: 10\n",
            "Generation 26, Best Fitness: 10\n",
            "Generation 27, Best Fitness: 10\n",
            "Generation 28, Best Fitness: 10\n",
            "Generation 29, Best Fitness: 10\n",
            "Generation 30, Best Fitness: 10\n",
            "Generation 31, Best Fitness: 10\n",
            "Generation 32, Best Fitness: 10\n",
            "Generation 33, Best Fitness: 10\n",
            "Generation 34, Best Fitness: 10\n",
            "Generation 35, Best Fitness: 10\n",
            "Generation 36, Best Fitness: 10\n",
            "Generation 37, Best Fitness: 10\n",
            "Generation 38, Best Fitness: 10\n",
            "Generation 39, Best Fitness: 10\n",
            "Generation 40, Best Fitness: 10\n",
            "Generation 41, Best Fitness: 10\n",
            "Generation 42, Best Fitness: 10\n",
            "Generation 43, Best Fitness: 10\n",
            "Generation 44, Best Fitness: 10\n",
            "Generation 45, Best Fitness: 10\n",
            "Generation 46, Best Fitness: 10\n",
            "Generation 47, Best Fitness: 10\n",
            "Generation 48, Best Fitness: 10\n",
            "Generation 49, Best Fitness: 10\n",
            "Generation 50, Best Fitness: 10\n",
            "Generation 51, Best Fitness: 10\n",
            "Generation 52, Best Fitness: 10\n",
            "Generation 53, Best Fitness: 10\n",
            "Generation 54, Best Fitness: 10\n",
            "Generation 55, Best Fitness: 10\n",
            "Generation 56, Best Fitness: 10\n",
            "Generation 57, Best Fitness: 10\n",
            "Generation 58, Best Fitness: 10\n",
            "Generation 59, Best Fitness: 10\n",
            "Generation 60, Best Fitness: 10\n",
            "Generation 61, Best Fitness: 10\n",
            "Generation 62, Best Fitness: 10\n",
            "Generation 63, Best Fitness: 10\n",
            "Generation 64, Best Fitness: 10\n",
            "Generation 65, Best Fitness: 10\n",
            "Generation 66, Best Fitness: 10\n",
            "Generation 67, Best Fitness: 10\n",
            "Generation 68, Best Fitness: 10\n",
            "Generation 69, Best Fitness: 10\n",
            "Generation 70, Best Fitness: 10\n",
            "Generation 71, Best Fitness: 10\n",
            "Generation 72, Best Fitness: 10\n",
            "Generation 73, Best Fitness: 10\n",
            "Generation 74, Best Fitness: 10\n",
            "Generation 75, Best Fitness: 10\n",
            "Generation 76, Best Fitness: 10\n",
            "Generation 77, Best Fitness: 10\n",
            "Generation 78, Best Fitness: 10\n",
            "Generation 79, Best Fitness: 10\n",
            "Generation 80, Best Fitness: 10\n",
            "Generation 81, Best Fitness: 10\n",
            "Generation 82, Best Fitness: 10\n",
            "Generation 83, Best Fitness: 10\n",
            "Generation 84, Best Fitness: 10\n",
            "Generation 85, Best Fitness: 10\n",
            "Generation 86, Best Fitness: 10\n",
            "Generation 87, Best Fitness: 10\n",
            "Generation 88, Best Fitness: 10\n",
            "Generation 89, Best Fitness: 10\n",
            "Generation 90, Best Fitness: 10\n",
            "Generation 91, Best Fitness: 10\n",
            "Generation 92, Best Fitness: 10\n",
            "Generation 93, Best Fitness: 10\n",
            "Generation 94, Best Fitness: 10\n",
            "Generation 95, Best Fitness: 10\n",
            "Generation 96, Best Fitness: 10\n",
            "Generation 97, Best Fitness: 10\n",
            "Generation 98, Best Fitness: 10\n",
            "Generation 99, Best Fitness: 10\n",
            "Generation 100, Best Fitness: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Adaptive Genetic Algorithm:\n",
        "\n",
        "Adjusts genetic operators (crossover rate, mutation rate) during evolution based on the population's performance to balance exploration and exploitation."
      ],
      "metadata": {
        "id": "6OfF1fqcSFYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class AdaptiveGeneticAlgorithm:\n",
        "    def __init__(self, population_size, initial_crossover_rate, initial_mutation_rate, tournament_size):\n",
        "        self.population_size = population_size\n",
        "        self.crossover_rate = initial_crossover_rate\n",
        "        self.mutation_rate = initial_mutation_rate\n",
        "        self.tournament_size = tournament_size\n",
        "        self.population = []\n",
        "\n",
        "    def initialize_population(self, individual_generator):\n",
        "        self.population = [individual_generator() for _ in range(self.population_size)]\n",
        "\n",
        "    def evolve(self, fitness_func, num_generations):\n",
        "        for generation in range(num_generations):\n",
        "            new_population = []\n",
        "            for _ in range(self.population_size):\n",
        "                # Select parents for crossover using tournament selection\n",
        "                parent1 = self.tournament_selection(fitness_func)\n",
        "                parent2 = self.tournament_selection(fitness_func)\n",
        "\n",
        "                # Apply crossover to create offspring\n",
        "                offspring = self.crossover(parent1, parent2)\n",
        "\n",
        "                # Apply mutation to the offspring\n",
        "                offspring = self.mutate(offspring)\n",
        "\n",
        "                # Add offspring to the new population\n",
        "                new_population.append(offspring)\n",
        "\n",
        "            # Replace individuals in the population with new population\n",
        "            self.replace_population(new_population, fitness_func)\n",
        "\n",
        "            # Adapt genetic operators based on population's performance\n",
        "            self.adapt_genetic_operators(generation, fitness_func, new_population)\n",
        "\n",
        "            # Optional: Monitor or record the best individual in this generation\n",
        "            best_individual = max(self.population, key=fitness_func)\n",
        "            print(f\"Generation {generation + 1}, Best Fitness: {fitness_func(best_individual)}, Crossover Rate: {self.crossover_rate}, Mutation Rate: {self.mutation_rate}\")\n",
        "\n",
        "    def tournament_selection(self, fitness_func):\n",
        "        # Randomly select individuals for the tournament\n",
        "        tournament_contestants = random.sample(self.population, self.tournament_size)\n",
        "        # Return the best contestant based on fitness\n",
        "        return max(tournament_contestants, key=fitness_func)\n",
        "\n",
        "    def crossover(self, parent1, parent2):\n",
        "        # Example: Single-point crossover\n",
        "        crossover_point = random.randint(0, min(len(parent1), len(parent2)) - 1)\n",
        "        return parent1[:crossover_point] + parent2[crossover_point:]\n",
        "\n",
        "    def mutate(self, individual):\n",
        "        # Example: Bit-wise mutation (flipping a random bit)\n",
        "        mutated_individual = list(individual)\n",
        "        for i in range(len(mutated_individual)):\n",
        "            if random.random() < self.mutation_rate:\n",
        "                mutated_individual[i] = 1 - mutated_individual[i]  # Flip 0 to 1 or 1 to 0\n",
        "        return tuple(mutated_individual)\n",
        "\n",
        "    def replace_population(self, new_population, fitness_func):\n",
        "        # Replace less fit individuals in the current population with new population\n",
        "        for i in range(self.population_size):\n",
        "            if fitness_func(new_population[i]) > fitness_func(self.population[i]):\n",
        "                self.population[i] = new_population[i]\n",
        "\n",
        "    def adapt_genetic_operators(self, generation, fitness_func, new_population):\n",
        "        # Example adaptation mechanism: Adjust crossover and mutation rates based on generation and population's performance\n",
        "        # Adjust crossover rate: Decrease over time\n",
        "        self.crossover_rate = max(0.1, self.crossover_rate - 0.01)\n",
        "\n",
        "        # Adjust mutation rate: Increase if fitness has not improved recently\n",
        "        if generation > 0:\n",
        "            prev_best_fitness = fitness_func(max(self.population, key=fitness_func))\n",
        "            current_best_fitness = fitness_func(max(new_population, key=fitness_func))\n",
        "            if current_best_fitness <= prev_best_fitness:\n",
        "                self.mutation_rate = min(0.5, self.mutation_rate + 0.01)\n",
        "\n",
        "# Example usage:\n",
        "def generate_random_individual():\n",
        "    # Generate a random individual (e.g., binary string)\n",
        "    return tuple(random.randint(0, 1) for _ in range(10))  # 10-bit individual\n",
        "\n",
        "def calculate_fitness(individual):\n",
        "    # Example fitness function (count of 1s in the individual)\n",
        "    return sum(individual)\n",
        "\n",
        "# Initialize and run the adaptive genetic algorithm\n",
        "aga = AdaptiveGeneticAlgorithm(population_size=50, initial_crossover_rate=0.8, initial_mutation_rate=0.01, tournament_size=3)\n",
        "aga.initialize_population(generate_random_individual)\n",
        "aga.evolve(calculate_fitness, num_generations=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzOKZH8PSGRu",
        "outputId": "edb089b4-2dec-494a-a377-c04465dfe6ba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1, Best Fitness: 10, Crossover Rate: 0.79, Mutation Rate: 0.01\n",
            "Generation 2, Best Fitness: 10, Crossover Rate: 0.78, Mutation Rate: 0.02\n",
            "Generation 3, Best Fitness: 10, Crossover Rate: 0.77, Mutation Rate: 0.03\n",
            "Generation 4, Best Fitness: 10, Crossover Rate: 0.76, Mutation Rate: 0.04\n",
            "Generation 5, Best Fitness: 10, Crossover Rate: 0.75, Mutation Rate: 0.05\n",
            "Generation 6, Best Fitness: 10, Crossover Rate: 0.74, Mutation Rate: 0.060000000000000005\n",
            "Generation 7, Best Fitness: 10, Crossover Rate: 0.73, Mutation Rate: 0.07\n",
            "Generation 8, Best Fitness: 10, Crossover Rate: 0.72, Mutation Rate: 0.08\n",
            "Generation 9, Best Fitness: 10, Crossover Rate: 0.71, Mutation Rate: 0.09\n",
            "Generation 10, Best Fitness: 10, Crossover Rate: 0.7, Mutation Rate: 0.09999999999999999\n",
            "Generation 11, Best Fitness: 10, Crossover Rate: 0.69, Mutation Rate: 0.10999999999999999\n",
            "Generation 12, Best Fitness: 10, Crossover Rate: 0.6799999999999999, Mutation Rate: 0.11999999999999998\n",
            "Generation 13, Best Fitness: 10, Crossover Rate: 0.6699999999999999, Mutation Rate: 0.12999999999999998\n",
            "Generation 14, Best Fitness: 10, Crossover Rate: 0.6599999999999999, Mutation Rate: 0.13999999999999999\n",
            "Generation 15, Best Fitness: 10, Crossover Rate: 0.6499999999999999, Mutation Rate: 0.15\n",
            "Generation 16, Best Fitness: 10, Crossover Rate: 0.6399999999999999, Mutation Rate: 0.16\n",
            "Generation 17, Best Fitness: 10, Crossover Rate: 0.6299999999999999, Mutation Rate: 0.17\n",
            "Generation 18, Best Fitness: 10, Crossover Rate: 0.6199999999999999, Mutation Rate: 0.18000000000000002\n",
            "Generation 19, Best Fitness: 10, Crossover Rate: 0.6099999999999999, Mutation Rate: 0.19000000000000003\n",
            "Generation 20, Best Fitness: 10, Crossover Rate: 0.5999999999999999, Mutation Rate: 0.20000000000000004\n",
            "Generation 21, Best Fitness: 10, Crossover Rate: 0.5899999999999999, Mutation Rate: 0.21000000000000005\n",
            "Generation 22, Best Fitness: 10, Crossover Rate: 0.5799999999999998, Mutation Rate: 0.22000000000000006\n",
            "Generation 23, Best Fitness: 10, Crossover Rate: 0.5699999999999998, Mutation Rate: 0.23000000000000007\n",
            "Generation 24, Best Fitness: 10, Crossover Rate: 0.5599999999999998, Mutation Rate: 0.24000000000000007\n",
            "Generation 25, Best Fitness: 10, Crossover Rate: 0.5499999999999998, Mutation Rate: 0.25000000000000006\n",
            "Generation 26, Best Fitness: 10, Crossover Rate: 0.5399999999999998, Mutation Rate: 0.26000000000000006\n",
            "Generation 27, Best Fitness: 10, Crossover Rate: 0.5299999999999998, Mutation Rate: 0.2700000000000001\n",
            "Generation 28, Best Fitness: 10, Crossover Rate: 0.5199999999999998, Mutation Rate: 0.2800000000000001\n",
            "Generation 29, Best Fitness: 10, Crossover Rate: 0.5099999999999998, Mutation Rate: 0.2900000000000001\n",
            "Generation 30, Best Fitness: 10, Crossover Rate: 0.4999999999999998, Mutation Rate: 0.3000000000000001\n",
            "Generation 31, Best Fitness: 10, Crossover Rate: 0.48999999999999977, Mutation Rate: 0.3100000000000001\n",
            "Generation 32, Best Fitness: 10, Crossover Rate: 0.47999999999999976, Mutation Rate: 0.3200000000000001\n",
            "Generation 33, Best Fitness: 10, Crossover Rate: 0.46999999999999975, Mutation Rate: 0.3300000000000001\n",
            "Generation 34, Best Fitness: 10, Crossover Rate: 0.45999999999999974, Mutation Rate: 0.34000000000000014\n",
            "Generation 35, Best Fitness: 10, Crossover Rate: 0.44999999999999973, Mutation Rate: 0.35000000000000014\n",
            "Generation 36, Best Fitness: 10, Crossover Rate: 0.4399999999999997, Mutation Rate: 0.36000000000000015\n",
            "Generation 37, Best Fitness: 10, Crossover Rate: 0.4299999999999997, Mutation Rate: 0.37000000000000016\n",
            "Generation 38, Best Fitness: 10, Crossover Rate: 0.4199999999999997, Mutation Rate: 0.38000000000000017\n",
            "Generation 39, Best Fitness: 10, Crossover Rate: 0.4099999999999997, Mutation Rate: 0.3900000000000002\n",
            "Generation 40, Best Fitness: 10, Crossover Rate: 0.3999999999999997, Mutation Rate: 0.4000000000000002\n",
            "Generation 41, Best Fitness: 10, Crossover Rate: 0.3899999999999997, Mutation Rate: 0.4100000000000002\n",
            "Generation 42, Best Fitness: 10, Crossover Rate: 0.37999999999999967, Mutation Rate: 0.4200000000000002\n",
            "Generation 43, Best Fitness: 10, Crossover Rate: 0.36999999999999966, Mutation Rate: 0.4300000000000002\n",
            "Generation 44, Best Fitness: 10, Crossover Rate: 0.35999999999999965, Mutation Rate: 0.4400000000000002\n",
            "Generation 45, Best Fitness: 10, Crossover Rate: 0.34999999999999964, Mutation Rate: 0.45000000000000023\n",
            "Generation 46, Best Fitness: 10, Crossover Rate: 0.33999999999999964, Mutation Rate: 0.46000000000000024\n",
            "Generation 47, Best Fitness: 10, Crossover Rate: 0.3299999999999996, Mutation Rate: 0.47000000000000025\n",
            "Generation 48, Best Fitness: 10, Crossover Rate: 0.3199999999999996, Mutation Rate: 0.48000000000000026\n",
            "Generation 49, Best Fitness: 10, Crossover Rate: 0.3099999999999996, Mutation Rate: 0.49000000000000027\n",
            "Generation 50, Best Fitness: 10, Crossover Rate: 0.2999999999999996, Mutation Rate: 0.5\n",
            "Generation 51, Best Fitness: 10, Crossover Rate: 0.2899999999999996, Mutation Rate: 0.5\n",
            "Generation 52, Best Fitness: 10, Crossover Rate: 0.2799999999999996, Mutation Rate: 0.5\n",
            "Generation 53, Best Fitness: 10, Crossover Rate: 0.2699999999999996, Mutation Rate: 0.5\n",
            "Generation 54, Best Fitness: 10, Crossover Rate: 0.25999999999999956, Mutation Rate: 0.5\n",
            "Generation 55, Best Fitness: 10, Crossover Rate: 0.24999999999999956, Mutation Rate: 0.5\n",
            "Generation 56, Best Fitness: 10, Crossover Rate: 0.23999999999999955, Mutation Rate: 0.5\n",
            "Generation 57, Best Fitness: 10, Crossover Rate: 0.22999999999999954, Mutation Rate: 0.5\n",
            "Generation 58, Best Fitness: 10, Crossover Rate: 0.21999999999999953, Mutation Rate: 0.5\n",
            "Generation 59, Best Fitness: 10, Crossover Rate: 0.20999999999999952, Mutation Rate: 0.5\n",
            "Generation 60, Best Fitness: 10, Crossover Rate: 0.1999999999999995, Mutation Rate: 0.5\n",
            "Generation 61, Best Fitness: 10, Crossover Rate: 0.1899999999999995, Mutation Rate: 0.5\n",
            "Generation 62, Best Fitness: 10, Crossover Rate: 0.1799999999999995, Mutation Rate: 0.5\n",
            "Generation 63, Best Fitness: 10, Crossover Rate: 0.16999999999999948, Mutation Rate: 0.5\n",
            "Generation 64, Best Fitness: 10, Crossover Rate: 0.15999999999999948, Mutation Rate: 0.5\n",
            "Generation 65, Best Fitness: 10, Crossover Rate: 0.14999999999999947, Mutation Rate: 0.5\n",
            "Generation 66, Best Fitness: 10, Crossover Rate: 0.13999999999999946, Mutation Rate: 0.5\n",
            "Generation 67, Best Fitness: 10, Crossover Rate: 0.12999999999999945, Mutation Rate: 0.5\n",
            "Generation 68, Best Fitness: 10, Crossover Rate: 0.11999999999999945, Mutation Rate: 0.5\n",
            "Generation 69, Best Fitness: 10, Crossover Rate: 0.10999999999999946, Mutation Rate: 0.5\n",
            "Generation 70, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 71, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 72, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 73, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 74, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 75, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 76, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 77, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 78, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 79, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 80, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 81, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 82, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 83, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 84, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 85, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 86, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 87, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 88, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 89, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 90, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 91, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 92, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 93, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 94, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 95, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 96, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 97, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 98, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 99, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n",
            "Generation 100, Best Fitness: 10, Crossover Rate: 0.1, Mutation Rate: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Parallel Genetic Algorithm:\n",
        "\n",
        "Utilizes multiple processors or computers to evaluate individuals in parallel, speeding up the search process."
      ],
      "metadata": {
        "id": "wZOo4Um4UBO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import multiprocessing\n",
        "\n",
        "class ParallelGeneticAlgorithm:\n",
        "    def __init__(self, population_size, num_processes, crossover_rate, mutation_rate, tournament_size):\n",
        "        self.population_size = population_size\n",
        "        self.num_processes = num_processes\n",
        "        self.crossover_rate = crossover_rate\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.tournament_size = tournament_size\n",
        "        self.population = []\n",
        "\n",
        "    def initialize_population(self, individual_generator):\n",
        "        self.population = [individual_generator() for _ in range(self.population_size)]\n",
        "\n",
        "    def evolve(self, fitness_func, num_generations):\n",
        "        pool = multiprocessing.Pool(self.num_processes)\n",
        "\n",
        "        for generation in range(num_generations):\n",
        "            # Evaluate fitness of each individual in parallel\n",
        "            fitness_results = pool.map(fitness_func, self.population)\n",
        "            fitness_dict = {ind: fit for ind, fit in zip(self.population, fitness_results)}\n",
        "\n",
        "            new_population = []\n",
        "            for _ in range(self.population_size):\n",
        "                # Select parents for crossover using tournament selection\n",
        "                parent1 = self.tournament_selection(fitness_dict)\n",
        "                parent2 = self.tournament_selection(fitness_dict)\n",
        "\n",
        "                # Apply crossover to create offspring\n",
        "                offspring = self.crossover(parent1, parent2)\n",
        "\n",
        "                # Apply mutation to the offspring\n",
        "                offspring = self.mutate(offspring)\n",
        "\n",
        "                # Add offspring to the new population\n",
        "                new_population.append(offspring)\n",
        "\n",
        "            # Replace individuals in the population with new population\n",
        "            self.population = new_population\n",
        "\n",
        "            # Optional: Monitor or record the best individual in this generation\n",
        "            best_individual = max(self.population, key=fitness_func)\n",
        "            best_fitness = fitness_func(best_individual)\n",
        "            print(f\"Generation {generation + 1}, Best Fitness: {best_fitness}\")\n",
        "\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "\n",
        "    def tournament_selection(self, fitness_dict):\n",
        "        # Randomly select individuals for the tournament\n",
        "        tournament_contestants = random.sample(list(fitness_dict.keys()), self.tournament_size)\n",
        "        # Return the best contestant based on fitness\n",
        "        return max(tournament_contestants, key=lambda x: fitness_dict[x])\n",
        "\n",
        "    def crossover(self, parent1, parent2):\n",
        "        # Example: Single-point crossover\n",
        "        crossover_point = random.randint(0, min(len(parent1), len(parent2)) - 1)\n",
        "        return parent1[:crossover_point] + parent2[crossover_point:]\n",
        "\n",
        "    def mutate(self, individual):\n",
        "        # Example: Bit-wise mutation (flipping a random bit)\n",
        "        mutated_individual = list(individual)\n",
        "        for i in range(len(mutated_individual)):\n",
        "            if random.random() < self.mutation_rate:\n",
        "                mutated_individual[i] = 1 - mutated_individual[i]  # Flip 0 to 1 or 1 to 0\n",
        "        return tuple(mutated_individual)\n",
        "\n",
        "# Example usage:\n",
        "def generate_random_individual():\n",
        "    # Generate a random individual (e.g., binary string)\n",
        "    return tuple(random.randint(0, 1) for _ in range(10))  # 10-bit individual\n",
        "\n",
        "def calculate_fitness_parallel(individual):\n",
        "    # Example fitness function (count of 1s in the individual)\n",
        "    return sum(individual)\n",
        "\n",
        "# Initialize and run the parallel genetic algorithm\n",
        "pga = ParallelGeneticAlgorithm(population_size=50, num_processes=4, crossover_rate=0.8, mutation_rate=0.01, tournament_size=3)\n",
        "pga.initialize_population(generate_random_individual)\n",
        "pga.evolve(calculate_fitness_parallel, num_generations=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cybby-7EUFru",
        "outputId": "d0128723-675f-4ea1-b488-26a26ef07985"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1, Best Fitness: 9\n",
            "Generation 2, Best Fitness: 10\n",
            "Generation 3, Best Fitness: 10\n",
            "Generation 4, Best Fitness: 10\n",
            "Generation 5, Best Fitness: 10\n",
            "Generation 6, Best Fitness: 10\n",
            "Generation 7, Best Fitness: 10\n",
            "Generation 8, Best Fitness: 10\n",
            "Generation 9, Best Fitness: 10\n",
            "Generation 10, Best Fitness: 10\n",
            "Generation 11, Best Fitness: 10\n",
            "Generation 12, Best Fitness: 10\n",
            "Generation 13, Best Fitness: 10\n",
            "Generation 14, Best Fitness: 10\n",
            "Generation 15, Best Fitness: 10\n",
            "Generation 16, Best Fitness: 10\n",
            "Generation 17, Best Fitness: 10\n",
            "Generation 18, Best Fitness: 10\n",
            "Generation 19, Best Fitness: 10\n",
            "Generation 20, Best Fitness: 10\n",
            "Generation 21, Best Fitness: 10\n",
            "Generation 22, Best Fitness: 10\n",
            "Generation 23, Best Fitness: 10\n",
            "Generation 24, Best Fitness: 10\n",
            "Generation 25, Best Fitness: 10\n",
            "Generation 26, Best Fitness: 10\n",
            "Generation 27, Best Fitness: 10\n",
            "Generation 28, Best Fitness: 10\n",
            "Generation 29, Best Fitness: 10\n",
            "Generation 30, Best Fitness: 10\n",
            "Generation 31, Best Fitness: 10\n",
            "Generation 32, Best Fitness: 10\n",
            "Generation 33, Best Fitness: 10\n",
            "Generation 34, Best Fitness: 10\n",
            "Generation 35, Best Fitness: 10\n",
            "Generation 36, Best Fitness: 10\n",
            "Generation 37, Best Fitness: 10\n",
            "Generation 38, Best Fitness: 10\n",
            "Generation 39, Best Fitness: 10\n",
            "Generation 40, Best Fitness: 10\n",
            "Generation 41, Best Fitness: 10\n",
            "Generation 42, Best Fitness: 10\n",
            "Generation 43, Best Fitness: 10\n",
            "Generation 44, Best Fitness: 10\n",
            "Generation 45, Best Fitness: 10\n",
            "Generation 46, Best Fitness: 10\n",
            "Generation 47, Best Fitness: 10\n",
            "Generation 48, Best Fitness: 10\n",
            "Generation 49, Best Fitness: 10\n",
            "Generation 50, Best Fitness: 10\n",
            "Generation 51, Best Fitness: 10\n",
            "Generation 52, Best Fitness: 10\n",
            "Generation 53, Best Fitness: 10\n",
            "Generation 54, Best Fitness: 10\n",
            "Generation 55, Best Fitness: 10\n",
            "Generation 56, Best Fitness: 10\n",
            "Generation 57, Best Fitness: 10\n",
            "Generation 58, Best Fitness: 10\n",
            "Generation 59, Best Fitness: 10\n",
            "Generation 60, Best Fitness: 10\n",
            "Generation 61, Best Fitness: 10\n",
            "Generation 62, Best Fitness: 10\n",
            "Generation 63, Best Fitness: 10\n",
            "Generation 64, Best Fitness: 10\n",
            "Generation 65, Best Fitness: 10\n",
            "Generation 66, Best Fitness: 10\n",
            "Generation 67, Best Fitness: 10\n",
            "Generation 68, Best Fitness: 10\n",
            "Generation 69, Best Fitness: 10\n",
            "Generation 70, Best Fitness: 10\n",
            "Generation 71, Best Fitness: 10\n",
            "Generation 72, Best Fitness: 10\n",
            "Generation 73, Best Fitness: 10\n",
            "Generation 74, Best Fitness: 10\n",
            "Generation 75, Best Fitness: 10\n",
            "Generation 76, Best Fitness: 10\n",
            "Generation 77, Best Fitness: 10\n",
            "Generation 78, Best Fitness: 10\n",
            "Generation 79, Best Fitness: 10\n",
            "Generation 80, Best Fitness: 10\n",
            "Generation 81, Best Fitness: 10\n",
            "Generation 82, Best Fitness: 10\n",
            "Generation 83, Best Fitness: 10\n",
            "Generation 84, Best Fitness: 10\n",
            "Generation 85, Best Fitness: 10\n",
            "Generation 86, Best Fitness: 10\n",
            "Generation 87, Best Fitness: 10\n",
            "Generation 88, Best Fitness: 10\n",
            "Generation 89, Best Fitness: 10\n",
            "Generation 90, Best Fitness: 10\n",
            "Generation 91, Best Fitness: 10\n",
            "Generation 92, Best Fitness: 10\n",
            "Generation 93, Best Fitness: 10\n",
            "Generation 94, Best Fitness: 10\n",
            "Generation 95, Best Fitness: 10\n",
            "Generation 96, Best Fitness: 10\n",
            "Generation 97, Best Fitness: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 98, Best Fitness: 10\n",
            "Generation 99, Best Fitness: 10\n",
            "Generation 100, Best Fitness: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Genetic Algorithms (GAs) and Neural Networks"
      ],
      "metadata": {
        "id": "QKRBBLEpUcJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install deap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBPZ3KkbVeL8",
        "outputId": "a1333398-85e3-41c7-9429-feea78a617ac"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.25.2)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from deap import creator, base, tools, algorithms\n",
        "\n",
        "# Load iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define the neural network evaluation function\n",
        "def evaluate_nn(individual):\n",
        "    # Unpack individual (neural network architecture)\n",
        "    hidden_units = individual[0]\n",
        "\n",
        "    # Create MLPClassifier with the specified hidden layer size\n",
        "    clf = MLPClassifier(hidden_layer_sizes=(hidden_units,), random_state=42)\n",
        "\n",
        "    try:\n",
        "        # Train the classifier\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate accuracy on the test set\n",
        "        y_pred = clf.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during training: {e}\")\n",
        "        accuracy = 0.0  # Set accuracy to 0 in case of training error\n",
        "\n",
        "    return accuracy,\n",
        "\n",
        "# Genetic Algorithm setup\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_int\", random.randint, 5, 50)  # Hidden layer size (neurons)\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_int, n=1)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)  # Blend crossover\n",
        "toolbox.register(\"mutate\", tools.mutUniformInt, low=5, up=50, indpb=0.1)  # Uniform mutation\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "toolbox.register(\"evaluate\", evaluate_nn)\n",
        "\n",
        "def main():\n",
        "    random.seed(42)\n",
        "\n",
        "    # Create initial population\n",
        "    population = toolbox.population(n=20)\n",
        "\n",
        "    # Define genetic algorithm parameters\n",
        "    cxpb, mutpb, ngen = 0.5, 0.2, 10  # Crossover probability, mutation probability, number of generations\n",
        "\n",
        "    # Execute genetic algorithm\n",
        "    for gen in range(ngen):\n",
        "        offspring = algorithms.varAnd(population, toolbox, cxpb, mutpb)\n",
        "\n",
        "        fits = toolbox.map(toolbox.evaluate, offspring)\n",
        "        for fit, ind in zip(fits, offspring):\n",
        "            ind.fitness.values = fit\n",
        "\n",
        "        population[:] = toolbox.select(offspring, k=len(population))\n",
        "\n",
        "    # Get the best individual\n",
        "    best_ind = tools.selBest(population, k=1)[0]\n",
        "    best_hidden_units = best_ind[0]\n",
        "\n",
        "    # Train the best neural network and evaluate on the test set\n",
        "    best_clf = MLPClassifier(hidden_layer_sizes=(best_hidden_units,), random_state=42)\n",
        "    best_clf.fit(X_train, y_train)\n",
        "    y_pred = best_clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Best Hidden Units: {best_hidden_units}\")\n",
        "    print(f\"Test Accuracy with Best Model: {accuracy:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY9U9LzUVYJs",
        "outputId": "be80a7e7-3fc3-46d2-eb91-a332b774bfec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
            "/usr/local/lib/python3.10/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: hidden_layer_sizes must be > 0, got [-0.07596741942461094].\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Error during training: 'float' object cannot be interpreted as an integer\n",
            "Best Hidden Units: 49\n",
            "Test Accuracy with Best Model: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}